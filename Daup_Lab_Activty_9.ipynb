{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DmL6je4qS3FU"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('/content/diabetes_data_upload.csv')"
      ],
      "metadata": {
        "id": "HG1M9-y6TNHR"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "NuibUXQeTRuE",
        "outputId": "1a492b0f-dbd4-4255-aa15-68346890db6d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Age  Gender Polyuria Polydipsia sudden weight loss weakness Polyphagia  \\\n",
              "0     40    Male       No        Yes                 No      Yes         No   \n",
              "1     58    Male       No         No                 No      Yes         No   \n",
              "2     41    Male      Yes         No                 No      Yes        Yes   \n",
              "3     45    Male       No         No                Yes      Yes        Yes   \n",
              "4     60    Male      Yes        Yes                Yes      Yes        Yes   \n",
              "..   ...     ...      ...        ...                ...      ...        ...   \n",
              "515   39  Female      Yes        Yes                Yes       No        Yes   \n",
              "516   48  Female      Yes        Yes                Yes      Yes        Yes   \n",
              "517   58  Female      Yes        Yes                Yes      Yes        Yes   \n",
              "518   32  Female       No         No                 No      Yes         No   \n",
              "519   42    Male       No         No                 No       No         No   \n",
              "\n",
              "    Genital thrush visual blurring Itching Irritability delayed healing  \\\n",
              "0               No              No     Yes           No             Yes   \n",
              "1               No             Yes      No           No              No   \n",
              "2               No              No     Yes           No             Yes   \n",
              "3              Yes              No     Yes           No             Yes   \n",
              "4               No             Yes     Yes          Yes             Yes   \n",
              "..             ...             ...     ...          ...             ...   \n",
              "515             No              No     Yes           No             Yes   \n",
              "516             No              No     Yes          Yes             Yes   \n",
              "517             No             Yes      No           No              No   \n",
              "518             No             Yes     Yes           No             Yes   \n",
              "519             No              No      No           No              No   \n",
              "\n",
              "    partial paresis muscle stiffness Alopecia Obesity     class  \n",
              "0                No              Yes      Yes     Yes  Positive  \n",
              "1               Yes               No      Yes      No  Positive  \n",
              "2                No              Yes      Yes      No  Positive  \n",
              "3                No               No       No      No  Positive  \n",
              "4               Yes              Yes      Yes     Yes  Positive  \n",
              "..              ...              ...      ...     ...       ...  \n",
              "515             Yes               No       No      No  Positive  \n",
              "516             Yes               No       No      No  Positive  \n",
              "517             Yes              Yes       No     Yes  Positive  \n",
              "518              No               No      Yes      No  Negative  \n",
              "519              No               No       No      No  Negative  \n",
              "\n",
              "[520 rows x 17 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2a1783e6-1ffa-4e6a-99a3-e3140d49c050\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Polyuria</th>\n",
              "      <th>Polydipsia</th>\n",
              "      <th>sudden weight loss</th>\n",
              "      <th>weakness</th>\n",
              "      <th>Polyphagia</th>\n",
              "      <th>Genital thrush</th>\n",
              "      <th>visual blurring</th>\n",
              "      <th>Itching</th>\n",
              "      <th>Irritability</th>\n",
              "      <th>delayed healing</th>\n",
              "      <th>partial paresis</th>\n",
              "      <th>muscle stiffness</th>\n",
              "      <th>Alopecia</th>\n",
              "      <th>Obesity</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>40</td>\n",
              "      <td>Male</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>58</td>\n",
              "      <td>Male</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>41</td>\n",
              "      <td>Male</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>45</td>\n",
              "      <td>Male</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>60</td>\n",
              "      <td>Male</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>515</th>\n",
              "      <td>39</td>\n",
              "      <td>Female</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>516</th>\n",
              "      <td>48</td>\n",
              "      <td>Female</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>517</th>\n",
              "      <td>58</td>\n",
              "      <td>Female</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>518</th>\n",
              "      <td>32</td>\n",
              "      <td>Female</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>519</th>\n",
              "      <td>42</td>\n",
              "      <td>Male</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>520 rows Ã— 17 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2a1783e6-1ffa-4e6a-99a3-e3140d49c050')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2a1783e6-1ffa-4e6a-99a3-e3140d49c050 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2a1783e6-1ffa-4e6a-99a3-e3140d49c050');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3847052d-7cc4-4d25-aa93-3936abc585ee\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3847052d-7cc4-4d25-aa93-3936abc585ee')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3847052d-7cc4-4d25-aa93-3936abc585ee button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_aadcd38f-97b0-46a5-b4a0-25616c3303a0\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_aadcd38f-97b0-46a5-b4a0-25616c3303a0 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 520,\n  \"fields\": [\n    {\n      \"column\": \"Age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12,\n        \"min\": 16,\n        \"max\": 90,\n        \"num_unique_values\": 51,\n        \"samples\": [\n          79,\n          90,\n          33\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Gender\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Female\",\n          \"Male\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Polyuria\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Yes\",\n          \"No\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Polydipsia\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"No\",\n          \"Yes\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sudden weight loss\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Yes\",\n          \"No\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"weakness\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"No\",\n          \"Yes\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Polyphagia\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Yes\",\n          \"No\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Genital thrush\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Yes\",\n          \"No\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"visual blurring\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Yes\",\n          \"No\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Itching\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"No\",\n          \"Yes\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Irritability\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Yes\",\n          \"No\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"delayed healing\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"No\",\n          \"Yes\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"partial paresis\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Yes\",\n          \"No\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"muscle stiffness\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"No\",\n          \"Yes\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Alopecia\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"No\",\n          \"Yes\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Obesity\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"No\",\n          \"Yes\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"class\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Negative\",\n          \"Positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
        "\n",
        "X = df.drop('class', axis=1)\n",
        "y = df['class']\n",
        "\n",
        "# Convert categorical features to numerical using one-hot encoding\n",
        "X = pd.get_dummies(X)\n",
        "\n",
        "y = y.map({'Negative': 0, 'Positive': 1})\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "# Train Logistic Regression\n",
        "logreg_model = LogisticRegression()\n",
        "logreg_model.fit(X_train, y_train)\n",
        "logreg_pred = logreg_model.predict(X_test)\n",
        "\n",
        "\n",
        "# Train Decision Tree\n",
        "dt_model = DecisionTreeClassifier()\n",
        "dt_model.fit(X_train, y_train)\n",
        "dt_pred = dt_model.predict(X_test)\n",
        "\n",
        "\n",
        "# Train Random Forest\n",
        "rf_model = RandomForestClassifier()\n",
        "rf_model.fit(X_train, y_train)\n",
        "rf_pred = rf_model.predict(X_test)\n",
        "\n",
        "\n",
        "# Evaluate the models\n",
        "def evaluate_model(y_true, y_pred):\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred)\n",
        "    recall = recall_score(y_true, y_pred)\n",
        "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
        "    false_negative_rate = fn / (fn + tp)\n",
        "    return accuracy, precision, recall, false_negative_rate\n",
        "\n",
        "logreg_accuracy, logreg_precision, logreg_recall, logreg_fnr = evaluate_model(y_test, logreg_pred)\n",
        "dt_accuracy, dt_precision, dt_recall, dt_fnr = evaluate_model(y_test, dt_pred)\n",
        "rf_accuracy, rf_precision, rf_recall, rf_fnr = evaluate_model(y_test, rf_pred)\n",
        "\n",
        "\n",
        "print(\"Logistic Regression:\")\n",
        "print(\"Accuracy:\", logreg_accuracy)\n",
        "print(\"Precision:\", logreg_precision)\n",
        "print(\"Recall:\", logreg_recall)\n",
        "print(\"False Negative Rate:\", logreg_fnr)\n",
        "print()\n",
        "\n",
        "print(\"Decision Tree:\")\n",
        "print(\"Accuracy:\", dt_accuracy)\n",
        "print(\"Precision:\", dt_precision)\n",
        "print(\"Recall:\", dt_recall)\n",
        "print(\"False Negative Rate:\", dt_fnr)\n",
        "print()\n",
        "\n",
        "print(\"Random Forest:\")\n",
        "print(\"Accuracy:\", rf_accuracy)\n",
        "print(\"Precision:\", rf_precision)\n",
        "print(\"Recall:\", rf_recall)\n",
        "print(\"False Negative Rate:\", rf_fnr)\n",
        "print()\n",
        "\n",
        "\n",
        "# Identify the model with the lowest false negative rate\n",
        "models = {\n",
        "    'Logistic Regression': logreg_fnr,\n",
        "    'Decision Tree': dt_fnr,\n",
        "    'Random Forest': rf_fnr\n",
        "}\n",
        "best_model = min(models, key=models.get)\n",
        "print(f\"The model with the lowest false negative rate is: {best_model}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yIQ210ddTuXY",
        "outputId": "27350516-0c95-4503-f369-792bcb764b51"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression:\n",
            "Accuracy: 0.9230769230769231\n",
            "Precision: 0.9315068493150684\n",
            "Recall: 0.9577464788732394\n",
            "False Negative Rate: 0.04225352112676056\n",
            "\n",
            "Decision Tree:\n",
            "Accuracy: 0.9615384615384616\n",
            "Precision: 0.9855072463768116\n",
            "Recall: 0.9577464788732394\n",
            "False Negative Rate: 0.04225352112676056\n",
            "\n",
            "Random Forest:\n",
            "Accuracy: 0.9903846153846154\n",
            "Precision: 1.0\n",
            "Recall: 0.9859154929577465\n",
            "False Negative Rate: 0.014084507042253521\n",
            "\n",
            "The model with the lowest false negative rate is: Random Forest\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import stats\n",
        "\n",
        "results_df = pd.DataFrame({'Age': df.iloc[y_test.index]['Age'],\n",
        "                           'True Label': y_test,\n",
        "                           'Predicted Label': logreg_pred})\n",
        "\n",
        "correctly_classified_diabetic = results_df[(results_df['True Label'] == 1) & (results_df['Predicted Label'] == 1)]['Age']\n",
        "misclassified_diabetic = results_df[(results_df['True Label'] == 1) & (results_df['Predicted Label'] == 0)]['Age']\n",
        "\n",
        "t_statistic, p_value = stats.ttest_ind(correctly_classified_diabetic, misclassified_diabetic)\n",
        "\n",
        "print(f\"T-statistic: {t_statistic}\")\n",
        "print(f\"P-value: {p_value}\")\n",
        "\n",
        "if p_value < 0.05:\n",
        "    print(\"There is a significant difference in mean age between correctly and misclassified diabetic patients.\")\n",
        "    print(\"Age might be a relevant feature for predicting diabetes.\")\n",
        "else:\n",
        "    print(\"There is no significant difference in mean age between correctly and misclassified diabetic patients.\")\n",
        "    print(\"Age might not be a strong predictor of diabetes in this context.\")\n",
        "\n",
        "print(\"\\n\")\n",
        "if logreg_fnr > dt_fnr or logreg_fnr > rf_fnr:\n",
        "  print(\"Consider using a different model like Decision Tree or Random Forest for better classification, especially if minimizing false negatives is a priority.\")\n",
        "else:\n",
        "  print(\"The logistic regression model is performing well.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xR_YX-PyUeVg",
        "outputId": "5a6eeb31-8104-44ac-c0c6-cccffc4452b4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "T-statistic: 1.3175831097449258\n",
            "P-value: 0.19200148354386326\n",
            "There is no significant difference in mean age between correctly and misclassified diabetic patients.\n",
            "Age might not be a strong predictor of diabetes in this context.\n",
            "\n",
            "\n",
            "Consider using a different model like Decision Tree or Random Forest for better classification, especially if minimizing false negatives is a priority.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
        "from scipy import stats\n",
        "\n",
        "# Evaluate the models for false positive rate\n",
        "def evaluate_model_fpr(y_true, y_pred):\n",
        "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
        "    false_positive_rate = fp / (fp + tn) if (fp + tn) > 0 else 0  # Handle division by zero\n",
        "    return false_positive_rate\n",
        "\n",
        "rf_fpr = evaluate_model_fpr(y_test, rf_pred)\n",
        "print(\"Random Forest False Positive Rate:\", rf_fpr)\n",
        "\n",
        "\n",
        "# One-Sample Z-Test for Random Forest\n",
        "if rf_fpr > 0.20:\n",
        "  z_statistic, p_value = stats.ztest(\n",
        "      [rf_fpr], value=0.20, alternative='larger'\n",
        "  )\n",
        "  print(\"One-Sample Z-Test for Random Forest FPR:\")\n",
        "  print(\"Z-statistic:\", z_statistic)\n",
        "  print(\"P-value:\", p_value)\n",
        "  if p_value < 0.05:\n",
        "      print(\"The false positive rate is significantly higher than 20%.\")\n",
        "\n",
        "\n",
        "# Gradient Boosting Model\n",
        "gb_model = GradientBoostingClassifier()\n",
        "gb_model.fit(X_train, y_train)\n",
        "gb_pred = gb_model.predict(X_test)\n",
        "gb_fpr = evaluate_model_fpr(y_test, gb_pred)\n",
        "print(\"\\nGradient Boosting False Positive Rate:\", gb_fpr)\n",
        "\n",
        "# Compare models\n",
        "if gb_fpr < rf_fpr:\n",
        "  print(\"Gradient Boosting Model performs better in reducing Type I errors compared to Random Forest.\")\n",
        "else:\n",
        "  print(\"Random Forest Model performs better in reducing Type I errors compared to Gradient Boosting.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHNfZn4x8Pov",
        "outputId": "d3e0f9d8-6e2c-412e-bf0f-72986a690f5f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest False Positive Rate: 0.0\n",
            "\n",
            "Gradient Boosting False Positive Rate: 0.0\n",
            "Random Forest Model performs better in reducing Type I errors compared to Gradient Boosting.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "\n",
        "# Train SVM\n",
        "svm_model = SVC(probability=True)\n",
        "svm_model.fit(X_train, y_train)\n",
        "svm_pred = svm_model.predict(X_test)\n",
        "\n",
        "\n",
        "# Train KNN\n",
        "knn_model = KNeighborsClassifier()\n",
        "knn_model.fit(X_train, y_train)\n",
        "knn_pred = knn_model.predict(X_test)\n",
        "\n",
        "\n",
        "# Evaluate SVM\n",
        "svm_accuracy, svm_precision, svm_recall, svm_fnr = evaluate_model(y_test, svm_pred)\n",
        "print(\"SVM:\")\n",
        "print(\"Accuracy:\", svm_accuracy)\n",
        "print(\"Precision:\", svm_precision)\n",
        "print(\"Recall:\", svm_recall)\n",
        "print(\"False Negative Rate:\", svm_fnr)\n",
        "print()\n",
        "\n",
        "# Evaluate KNN\n",
        "knn_accuracy, knn_precision, knn_recall, knn_fnr = evaluate_model(y_test, knn_pred)\n",
        "print(\"KNN:\")\n",
        "print(\"Accuracy:\", knn_accuracy)\n",
        "print(\"Precision:\", knn_precision)\n",
        "print(\"Recall:\", knn_recall)\n",
        "print(\"False Negative Rate:\", knn_fnr)\n",
        "print()\n",
        "\n",
        "from statsmodels.stats.proportion import proportions_ztest\n",
        "\n",
        "# Get the number of successes (false negatives) and trials for each model\n",
        "svm_fn = int(svm_fnr * len(y_test))  # Number of false negatives for SVM\n",
        "knn_fn = int(knn_fnr * len(y_test))  # Number of false negatives for KNN\n",
        "nobs = [len(y_test), len(y_test)]  # Number of trials for each model\n",
        "\n",
        "z_statistic, p_value = proportions_ztest([svm_fn, knn_fn], nobs)\n",
        "\n",
        "print(\"Z-Test between SVM and KNN FNR:\")\n",
        "print(\"Z-statistic:\", z_statistic)\n",
        "print(\"P-value:\", p_value)\n",
        "\n",
        "if p_value < 0.05:\n",
        "    print(\"The false negative rates of SVM and KNN are significantly different.\")\n",
        "else:\n",
        "    print(\"The false negative rates of SVM and KNN are not significantly different.\")\n",
        "\n",
        "print(\"Z-Test between SVM and KNN FNR:\")\n",
        "print(\"Z-statistic:\", z_statistic)\n",
        "print(\"P-value:\", p_value)\n",
        "\n",
        "if p_value < 0.05:\n",
        "    print(\"The false negative rates of SVM and KNN are significantly different.\")\n",
        "else:\n",
        "    print(\"The false negative rates of SVM and KNN are not significantly different.\")\n",
        "\n",
        "\n",
        "# Compare models and find the one with the lowest FNR\n",
        "models_fnr = {\n",
        "    \"Logistic Regression\": logreg_fnr,\n",
        "    \"SVM\": svm_fnr,\n",
        "    \"KNN\": knn_fnr,\n",
        "    \"Decision Tree\": dt_fnr,\n",
        "    \"Random Forest\": rf_fnr,\n",
        "}\n",
        "\n",
        "best_model_fnr = min(models_fnr, key=models_fnr.get)\n",
        "print(\n",
        "    f\"The model with the lowest false negative rate is: {best_model_fnr} with a FNR of {models_fnr[best_model_fnr]}\"\n",
        ")\n",
        "\n",
        "# Recommendation for real-world deployment\n",
        "print(\"\\nRecommendation for real-world deployment:\")\n",
        "\n",
        "if best_model_fnr == \"Logistic Regression\" or best_model_fnr == \"SVM\" or best_model_fnr == \"KNN\":\n",
        "    print(\n",
        "        f\"Based on the results, the {best_model_fnr} model is recommended for real-world deployment as it minimizes the risk of undiagnosed diabetes cases.\"\n",
        "    )\n",
        "else:\n",
        "    print(\n",
        "        f\"Based on the results, the {best_model_fnr} model is recommended for real-world deployment as it minimizes the risk of undiagnosed diabetes cases.\"\n",
        "    )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6phYoCSH8WSm",
        "outputId": "dbeda422-14f3-4c2c-f28e-12fda2d2b8ac"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM:\n",
            "Accuracy: 0.6826923076923077\n",
            "Precision: 0.6826923076923077\n",
            "Recall: 1.0\n",
            "False Negative Rate: 0.0\n",
            "\n",
            "KNN:\n",
            "Accuracy: 0.875\n",
            "Precision: 0.967741935483871\n",
            "Recall: 0.8450704225352113\n",
            "False Negative Rate: 0.15492957746478872\n",
            "\n",
            "Z-Test between SVM and KNN FNR:\n",
            "Z-statistic: -4.163331998932266\n",
            "P-value: 3.1363681444258854e-05\n",
            "The false negative rates of SVM and KNN are significantly different.\n",
            "Z-Test between SVM and KNN FNR:\n",
            "Z-statistic: -4.163331998932266\n",
            "P-value: 3.1363681444258854e-05\n",
            "The false negative rates of SVM and KNN are significantly different.\n",
            "The model with the lowest false negative rate is: SVM with a FNR of 0.0\n",
            "\n",
            "Recommendation for real-world deployment:\n",
            "Based on the results, the SVM model is recommended for real-world deployment as it minimizes the risk of undiagnosed diabetes cases.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Gradient Boosting Model\n",
        "gb_model = GradientBoostingClassifier()\n",
        "gb_model.fit(X_train, y_train)\n",
        "gb_pred = gb_model.predict(X_test)\n",
        "\n",
        "# Evaluate Gradient Boosting Model\n",
        "gb_accuracy, gb_precision, gb_recall, gb_fnr = evaluate_model(y_test, gb_pred)\n",
        "print(\"Gradient Boosting:\")\n",
        "print(\"Accuracy:\", gb_accuracy)\n",
        "print(\"Precision:\", gb_precision)\n",
        "print(\"Recall:\", gb_recall)\n",
        "print(\"False Negative Rate:\", gb_fnr)\n",
        "print()\n",
        "\n",
        "# Misclassification Analysis\n",
        "results_df = pd.DataFrame({\n",
        "    'Age': df.iloc[y_test.index]['Age'],\n",
        "    'True Label': y_test,\n",
        "    'Predicted Label': gb_pred\n",
        "})\n",
        "\n",
        "correctly_classified_diabetic = results_df[\n",
        "    (results_df['True Label'] == 1) & (results_df['Predicted Label'] == 1)]['Age']\n",
        "misclassified_diabetic = results_df[\n",
        "    (results_df['True Label'] == 1) & (results_df['Predicted Label'] == 0)]['Age']\n",
        "\n",
        "# Z-Test\n",
        "t_statistic, p_value = stats.ttest_ind(correctly_classified_diabetic,\n",
        "                                      misclassified_diabetic)\n",
        "\n",
        "print(f\"T-statistic: {t_statistic}\")\n",
        "print(f\"P-value: {p_value}\")\n",
        "\n",
        "if p_value < 0.05:\n",
        "    print(\n",
        "        \"There is a significant difference in mean age between correctly and misclassified diabetic patients.\"\n",
        "    )\n",
        "    print(\"Age might be a relevant feature for predicting diabetes.\")\n",
        "else:\n",
        "    print(\n",
        "        \"There is no significant difference in mean age between correctly and misclassified diabetic patients.\"\n",
        "    )\n",
        "    print(\"Age might not be a strong predictor of diabetes in this context.\")\n",
        "\n",
        "# Adjust the model to reduce Type II errors (if significant)\n",
        "if p_value < 0.05:\n",
        "    print(\n",
        "        \"\\nTo reduce Type II errors (false negatives), consider increasing the model's sensitivity.\"\n",
        "    )\n",
        "    print(\n",
        "        \"You can try adjusting the threshold for classification or exploring techniques like cost-sensitive learning to emphasize the cost of misclassifying diabetic patients.\"\n",
        "    )\n",
        "\n",
        "\n",
        "# Compare with Random Forest Model\n",
        "print(\"\\nComparing Gradient Boosting and Random Forest:\")\n",
        "print(\"Gradient Boosting False Negative Rate:\", gb_fnr)\n",
        "print(\"Random Forest False Negative Rate:\", rf_fnr)\n",
        "\n",
        "if gb_fnr < rf_fnr:\n",
        "    print(\n",
        "        \"Gradient Boosting Model has fewer Type II errors compared to Random Forest.\"\n",
        "    )\n",
        "    print(\n",
        "        \"Gradient Boosting is preferable for medical use, especially if minimizing false negatives is critical.\"\n",
        "    )\n",
        "else:\n",
        "    print(\n",
        "        \"Random Forest Model has fewer Type II errors compared to Gradient Boosting.\"\n",
        "    )\n",
        "    print(\n",
        "        \"Random Forest is preferable for medical use, especially if minimizing false negatives is critical.\"\n",
        "    )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQqaebYf8tC8",
        "outputId": "df23e897-4ea9-49ab-a086-8a71bb900075"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient Boosting:\n",
            "Accuracy: 0.9711538461538461\n",
            "Precision: 1.0\n",
            "Recall: 0.9577464788732394\n",
            "False Negative Rate: 0.04225352112676056\n",
            "\n",
            "T-statistic: 1.8205139869779916\n",
            "P-value: 0.07301728982680411\n",
            "There is no significant difference in mean age between correctly and misclassified diabetic patients.\n",
            "Age might not be a strong predictor of diabetes in this context.\n",
            "\n",
            "Comparing Gradient Boosting and Random Forest:\n",
            "Gradient Boosting False Negative Rate: 0.04225352112676056\n",
            "Random Forest False Negative Rate: 0.014084507042253521\n",
            "Random Forest Model has fewer Type II errors compared to Gradient Boosting.\n",
            "Random Forest is preferable for medical use, especially if minimizing false negatives is critical.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Train SVM\n",
        "svm_model = SVC(probability=True)\n",
        "svm_model.fit(X_train, y_train)\n",
        "svm_pred = svm_model.predict(X_test)\n",
        "\n",
        "# Train KNN\n",
        "knn_model = KNeighborsClassifier()\n",
        "knn_model.fit(X_train, y_train)\n",
        "knn_pred = knn_model.predict(X_test)\n",
        "\n",
        "# Evaluate SVM\n",
        "svm_accuracy, svm_precision, svm_recall, svm_fnr = evaluate_model(y_test, svm_pred)\n",
        "print(\"SVM:\")\n",
        "print(\"Accuracy:\", svm_accuracy)\n",
        "print(\"Precision:\", svm_precision)\n",
        "print(\"Recall:\", svm_recall)\n",
        "print(\"False Negative Rate:\", svm_fnr)\n",
        "print()\n",
        "\n",
        "# Evaluate KNN\n",
        "knn_accuracy, knn_precision, knn_recall, knn_fnr = evaluate_model(y_test, knn_pred)\n",
        "print(\"KNN:\")\n",
        "print(\"Accuracy:\", knn_accuracy)\n",
        "print(\"Precision:\", knn_precision)\n",
        "print(\"Recall:\", knn_recall)\n",
        "print(\"False Negative Rate:\", knn_fnr)\n",
        "print()\n",
        "\n",
        "# Get the number of successes (false negatives) and trials for each model\n",
        "svm_fn = int(svm_fnr * len(y_test))  # Number of false negatives for SVM\n",
        "knn_fn = int(knn_fnr * len(y_test))  # Number of false negatives for KNN\n",
        "nobs = [len(y_test), len(y_test)]  # Number of trials for each model\n",
        "\n",
        "z_statistic, p_value = proportions_ztest([svm_fn, knn_fn], nobs)\n",
        "\n",
        "print(\"Z-Test between SVM and KNN FNR:\")\n",
        "print(\"Z-statistic:\", z_statistic)\n",
        "print(\"P-value:\", p_value)\n",
        "\n",
        "if p_value < 0.05:\n",
        "    print(\"The false negative rates of SVM and KNN are significantly different.\")\n",
        "else:\n",
        "    print(\"The false negative rates of SVM and KNN are not significantly different.\")\n",
        "\n",
        "# Compare models and find the one with the lowest FNR\n",
        "models_fnr = {\n",
        "    \"Logistic Regression\": logreg_fnr,\n",
        "    \"SVM\": svm_fnr,\n",
        "    \"KNN\": knn_fnr,\n",
        "    \"Decision Tree\": dt_fnr,\n",
        "    \"Random Forest\": rf_fnr,\n",
        "}\n",
        "\n",
        "best_model_fnr = min(models_fnr, key=models_fnr.get)\n",
        "print(\n",
        "    f\"The model with the lowest false negative rate is: {best_model_fnr} with a FNR of {models_fnr[best_model_fnr]}\"\n",
        ")\n",
        "\n",
        "# Recommendation for real-world deployment\n",
        "print(\"\\nRecommendation for real-world deployment:\")\n",
        "\n",
        "if best_model_fnr == \"Logistic Regression\" or best_model_fnr == \"SVM\" or best_model_fnr == \"KNN\":\n",
        "    print(\n",
        "        f\"Based on the results, the {best_model_fnr} model is recommended for real-world deployment as it minimizes the risk of undiagnosed diabetes cases.\"\n",
        "    )\n",
        "else:\n",
        "    print(\n",
        "        f\"Based on the results, the {best_model_fnr} model is recommended for real-world deployment as it minimizes the risk of undiagnosed diabetes cases.\"\n",
        "    )\n",
        "\n",
        "# Train Gradient Boosting Model\n",
        "gb_model = GradientBoostingClassifier()\n",
        "gb_model.fit(X_train, y_train)\n",
        "gb_pred = gb_model.predict(X_test)\n",
        "\n",
        "# Evaluate Gradient Boosting Model\n",
        "gb_accuracy, gb_precision, gb_recall, gb_fnr = evaluate_model(y_test, gb_pred)\n",
        "print(\"Gradient Boosting:\")\n",
        "print(\"Accuracy:\", gb_accuracy)\n",
        "print(\"Precision:\", gb_precision)\n",
        "print(\"Recall:\", gb_recall)\n",
        "print(\"False Negative Rate:\", gb_fnr)\n",
        "print()\n",
        "\n",
        "# Misclassification Analysis\n",
        "results_df = pd.DataFrame({\n",
        "    'Age': df.iloc[y_test.index]['Age'],\n",
        "    'True Label': y_test,\n",
        "    'Predicted Label': gb_pred\n",
        "})\n",
        "\n",
        "correctly_classified_diabetic = results_df[\n",
        "    (results_df['True Label'] == 1) & (results_df['Predicted Label'] == 1)]['Age']\n",
        "misclassified_diabetic = results_df[\n",
        "    (results_df['True Label'] == 1) & (results_df['Predicted Label'] == 0)]['Age']\n",
        "\n",
        "# Z-Test\n",
        "t_statistic, p_value = stats.ttest_ind(correctly_classified_diabetic,\n",
        "                                      misclassified_diabetic)\n",
        "\n",
        "print(f\"T-statistic: {t_statistic}\")\n",
        "print(f\"P-value: {p_value}\")\n",
        "\n",
        "if p_value < 0.05:\n",
        "    print(\n",
        "        \"There is a significant difference in mean age between correctly and misclassified diabetic patients.\"\n",
        "    )\n",
        "    print(\"Age might be a relevant feature for predicting diabetes.\")\n",
        "else:\n",
        "    print(\n",
        "        \"There is no significant difference in mean age between correctly and misclassified diabetic patients.\"\n",
        "    )\n",
        "    print(\"Age might not be a strong predictor of diabetes in this context.\")\n",
        "\n",
        "# Adjust the model to reduce Type II errors (if significant)\n",
        "if p_value < 0.05:\n",
        "    print(\n",
        "        \"\\nTo reduce Type II errors (false negatives), consider increasing the model's sensitivity.\"\n",
        "    )\n",
        "    print(\n",
        "        \"You can try adjusting the threshold for classification or exploring techniques like cost-sensitive learning to emphasize the cost of misclassifying diabetic patients.\"\n",
        "    )\n",
        "\n",
        "# Compare with Random Forest Model\n",
        "print(\"\\nComparing Gradient Boosting and Random Forest:\")\n",
        "print(\"Gradient Boosting False Negative Rate:\", gb_fnr)\n",
        "print(\"Random Forest False Negative Rate:\", rf_fnr)\n",
        "\n",
        "if gb_fnr < rf_fnr:\n",
        "    print(\n",
        "        \"Gradient Boosting Model has fewer Type II errors compared to Random Forest.\"\n",
        "    )\n",
        "    print(\n",
        "        \"Gradient Boosting is preferable for medical use, especially if minimizing false negatives is critical.\"\n",
        "    )\n",
        "else:\n",
        "    print(\n",
        "        \"Random Forest Model has fewer Type II errors compared to Gradient Boosting.\"\n",
        "    )\n",
        "    print(\n",
        "        \"Random Forest is preferable for medical use, especially if minimizing false negatives is critical.\"\n",
        "    )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VjrdNsI382EG",
        "outputId": "0ae7bd6b-2e0c-4c12-9879-5634761c081f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM:\n",
            "Accuracy: 0.6826923076923077\n",
            "Precision: 0.6826923076923077\n",
            "Recall: 1.0\n",
            "False Negative Rate: 0.0\n",
            "\n",
            "KNN:\n",
            "Accuracy: 0.875\n",
            "Precision: 0.967741935483871\n",
            "Recall: 0.8450704225352113\n",
            "False Negative Rate: 0.15492957746478872\n",
            "\n",
            "Z-Test between SVM and KNN FNR:\n",
            "Z-statistic: -4.163331998932266\n",
            "P-value: 3.1363681444258854e-05\n",
            "The false negative rates of SVM and KNN are significantly different.\n",
            "The model with the lowest false negative rate is: SVM with a FNR of 0.0\n",
            "\n",
            "Recommendation for real-world deployment:\n",
            "Based on the results, the SVM model is recommended for real-world deployment as it minimizes the risk of undiagnosed diabetes cases.\n",
            "Gradient Boosting:\n",
            "Accuracy: 0.9711538461538461\n",
            "Precision: 1.0\n",
            "Recall: 0.9577464788732394\n",
            "False Negative Rate: 0.04225352112676056\n",
            "\n",
            "T-statistic: 1.8205139869779916\n",
            "P-value: 0.07301728982680411\n",
            "There is no significant difference in mean age between correctly and misclassified diabetic patients.\n",
            "Age might not be a strong predictor of diabetes in this context.\n",
            "\n",
            "Comparing Gradient Boosting and Random Forest:\n",
            "Gradient Boosting False Negative Rate: 0.04225352112676056\n",
            "Random Forest False Negative Rate: 0.014084507042253521\n",
            "Random Forest Model has fewer Type II errors compared to Gradient Boosting.\n",
            "Random Forest is preferable for medical use, especially if minimizing false negatives is critical.\n"
          ]
        }
      ]
    }
  ]
}